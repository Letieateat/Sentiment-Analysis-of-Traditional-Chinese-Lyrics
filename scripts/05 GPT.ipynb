{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-ih56i5qqcl",
        "outputId": "2506586d-61a5-4f30-b67c-5ffd474e84c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.25.1-py3-none-any.whl (312 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/312.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/312.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOnT_1pMVUNT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1st Prompt with Traditional Chinese example and English definition"
      ],
      "metadata": {
        "id": "wjOcsLR3vhy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "openai.api_key ='your api key'\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Letieateat/Sentiment-Analysis-on-Traditional-Chinese-Lyrics/main/dataset/final_sentiments.csv')\n",
        "\n",
        "def classify_emotion(lyrics):\n",
        "    prompt_text = f\"\"\"\n",
        "    You are trained to analyze and detect the sentiment of given lyrics and return the results in JSON format.\n",
        "    Example of Expected JSON Response Format:\n",
        "\n",
        "    sentiment_all: Tag from Task 1, sentiment_4: Tag from Task 2, sentiment_2: Tag from Task 3\n",
        "\n",
        "    Please detect the sentiment based on the following definition and examples:\n",
        "\n",
        "    Anxious: worried and nervous; eager to do something; wanting very much for something to happen\n",
        "    e.g. 該怎麽走 誰來告訴我\n",
        "\n",
        "    Angry: having a strong feeling against someone who has behaved badly, making you want to shout at them or hurt them\n",
        "    e.g. 你煩不煩 總考驗我多勇敢\n",
        "\n",
        "    Excited: feeling very happy and enthusiastic\n",
        "    e.g. 點起熱情的燭光 享受玫瑰的芳香\n",
        "\n",
        "    Happy: feeling, showing, or causing pleasure or satisfaction; full of enjoyment and pleasure\n",
        "    e.g. 一想到你呀 就讓我快樂\n",
        "\n",
        "    Relaxed: feeling happy and comfortable because nothing is worrying you; comfortable and informal\n",
        "    e.g. 人生很長 來得及任何事\n",
        "\n",
        "    Serene: peaceful and calm; worried by nothing\n",
        "    e.g. 讓我釋放 然後慢慢寬廣\n",
        "\n",
        "    Sad: unhappy or sorry; not satisfactory or pleasant\n",
        "    e.g. 我的淚光 承載不了\n",
        "\n",
        "    Negative: Anxious; Angry; Sad\n",
        "\n",
        "    Positive:  Excited; Happy; Serene; Relaxed\n",
        "\n",
        "    You'll be provided a dataset containing Traditional Chinese lyrics of different songs.\n",
        "    You need to complete 3 tasks. Select ONLY ONE TAG from the provided options for each task.\n",
        "    (Task 1 : sentiment_all) Tags:\n",
        "    - Anxious\n",
        "    - Angry\n",
        "    - Excited\n",
        "    - Happy\n",
        "    - Relaxed\n",
        "    - Serene\n",
        "    - Sad\n",
        "\n",
        "    (Task 2 : sentiment_4) Tags:\n",
        "    - Angry/Anxious\n",
        "    - Excited/Happy\n",
        "    - Serene/Relaxed\n",
        "    - Sad\n",
        "\n",
        "    (Task 3 : sentiment_2) Tags:\n",
        "    - Negative\n",
        "    - Positive\n",
        "\n",
        "    Lyrics: {lyrics}\n",
        "    \"\"\"\n",
        "    # Call the OpenAI API\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": prompt_text\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": lyrics\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "        if response.choices:\n",
        "            content = response.choices[0].message.content\n",
        "            data = json.loads(content)\n",
        "            # Normalize the data if it's not in the expected format\n",
        "            sentiment_all = normalize_sentiment(data.get(\"sentiment_all\", \"Unknown\"))\n",
        "            sentiment_4 = normalize_sentiment(data.get(\"sentiment_4\", \"Unknown\"))\n",
        "            sentiment_2 = normalize_sentiment(data.get(\"sentiment_2\", \"Unknown\"))\n",
        "            return {\n",
        "                \"gpt_sentiment_all\": data.get(\"sentiment_all\", \"Unknown\"),\n",
        "                \"gpt_sentiment_4\": data.get(\"sentiment_4\", \"Unknown\"),\n",
        "                \"gpt_sentiment_2\": data.get(\"sentiment_2\", \"Unknown\"),\n",
        "                \"original_response\": content\n",
        "            }\n",
        "        else:\n",
        "            return {\"gpt_sentiment_all\": None, \"gpt_sentiment_4\": None, \"gpt_sentiment_2\": None}\n",
        "    except Exception as e:\n",
        "        print(f\"Error handling response: {str(e)}\")\n",
        "        return {\"gpt_sentiment_all\": None, \"gpt_sentiment_4\": None, \"gpt_sentiment_2\": None}\n",
        "\n",
        "def normalize_sentiment(sentiment):\n",
        "    if isinstance(sentiment, list):\n",
        "        # Convert list to string if needed, or choose a handling strategy\n",
        "        return ', '.join(sentiment)\n",
        "    return sentiment\n",
        "\n",
        "# Apply to the dataset\n",
        "results = df['untokenized_lyrics'].apply(classify_emotion)\n",
        "\n",
        "# add results to dataframe\n",
        "results_df = pd.DataFrame(results.tolist())\n",
        "df = pd.concat([df, results_df], axis=1)\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "df.to_csv('gpt3.5_sentiments.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XBIkHG4hG-E",
        "outputId": "df4bf445-9216-439b-c2ed-cf95c1b3fa59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error handling response: Expecting value: line 1 column 1 (char 0)\n",
            "Error handling response: Expecting value: line 1 column 1 (char 0)\n",
            "  Track Name Artist Name                                       Artist Genre  \\\n",
            "0    1234567  Cheer Chen                 mandopop, taiwan singer-songwriter   \n",
            "1     100種生活    Crowd Lu   mandopop, taiwan indie, taiwan singer-songwriter   \n",
            "2      612星球       S.H.E  c-pop girl group, mandopop, taiwan idol pop, t...   \n",
            "3   80%完美的日子  Cheer Chen                 mandopop, taiwan singer-songwriter   \n",
            "4         一一   Hebe Tien                                           mandopop   \n",
            "\n",
            "   Popularity  Acousticness  Danceability  Duration (ms)  Energy  \\\n",
            "0          29         0.151         0.651         216560   0.659   \n",
            "1          44         0.650         0.721         287427   0.400   \n",
            "2          28         0.654         0.475         301347   0.432   \n",
            "3          28         0.632         0.454         278147   0.422   \n",
            "4          33         0.492         0.423         250733   0.289   \n",
            "\n",
            "   Instrumentalness  Key  ...  \\\n",
            "0          0.000026    5  ...   \n",
            "1          0.000000    9  ...   \n",
            "2          0.000000   11  ...   \n",
            "3          0.000192   11  ...   \n",
            "4          0.000034    0  ...   \n",
            "\n",
            "                                  untokenized_lyrics  \\\n",
            "0  時間過得快了些話題沒有終點夏天提早出現汗水濕透白襯衫我努力遮掩來到你的面前電話聲打斷了情緒香...   \n",
            "1  整個世界停止不轉動很寂寞走在海邊數着螢火蟲好困惑想要的生活怎麽有一百種不想掉進這深深漩渦整個...   \n",
            "2  滿園玫瑰我以爲找到我那一朵認真愛了卻狠狠刺傷我的雙手責備甚麼人也沒有用玫瑰都紅難免看錯望著天...   \n",
            "3  我捕捉精采的畫面可是一閉上眼顏色就退掉了我穿上最舒適的可是一脫下來身體都僵硬了我選擇我最想要...   \n",
            "4  偷信的人並不壞被愛的背對著愛回來我們從小聰明我們從大道理先出來我們把老實的我們把天才的一一膜拜一一   \n",
            "\n",
            "                                    tokenized_lyrics  \\\n",
            "0  ['時間', '過', '得', '快', '了', '些', '話題', '沒有', '終...   \n",
            "1  ['整', '個', '世界', '停止', '不', '轉動', '很', '寂寞', '...   \n",
            "2  ['滿', '園', '玫瑰', '我', '以爲', '找到', '我', '那', '一...   \n",
            "3  ['我', '捕捉', '精采', '的', '畫面', '可是', '一', '閉上', ...   \n",
            "4  ['偷信', '的', '人', '並', '不', '壞', '被', '愛', '的',...   \n",
            "\n",
            "                                        final_lyrics  human_all  \\\n",
            "0  時間 快 話題 終點 夏天 提早 出現 汗水 濕透 白 襯衫 努力 遮掩 來到 面前 電話聲...    Anxious   \n",
            "1  整 世界 停止 轉動 寂寞 走 海 數 着 螢火蟲 困惑 想要 生活 怎麽 一百 種 想 掉...    Anxious   \n",
            "2  滿 園 玫瑰 以爲 找到 朵 認真 愛 狠狠 刺傷 雙手 責備 玫瑰 紅 難免 看錯 天空 ...        Sad   \n",
            "3  捕捉 精采 畫面 閉上 眼 顏色 退掉 穿上 舒適 脫下來 身體 僵硬 選擇 想要 笑開 丟...    Anxious   \n",
            "4            偷信 壞 愛 背對 愛 回來 從小聰明 道理 先 老實 天才 一一 膜拜 一一    Relaxed   \n",
            "\n",
            "          human_4   human_2  gpt_sentiment_all gpt_sentiment_4  \\\n",
            "0   Angry/Anxious  Negative                Sad             Sad   \n",
            "1   Angry/Anxious  Negative                Sad             Sad   \n",
            "2             Sad  Negative                Sad             Sad   \n",
            "3   Angry/Anxious  Negative                Sad             Sad   \n",
            "4  Serene/Relaxed  Positive              Happy             Sad   \n",
            "\n",
            "  gpt_sentiment_2                                  original_response  \n",
            "0        Negative  {\\n    \"sentiment_all\": \"Sad\",\\n    \"sentiment...  \n",
            "1        Negative  {\\n    \"sentiment_all\": \"Sad\",\\n    \"sentiment...  \n",
            "2        Negative  {\\n    \"sentiment_all\": \"Sad\",\\n    \"sentiment...  \n",
            "3        Negative  {\\n    \"sentiment_all\": \"Sad\",\\n    \"sentiment...  \n",
            "4        Negative  {\\n    \"sentiment_all\": \"Happy\",\\n    \"sentime...  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "file_path = 'https://raw.githubusercontent.com/Letieateat/Sentiment-Analysis-on-Traditional-Chinese-Lyrics/main/dataset/gpt3.5_sentiments.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "LGepdhW7uXb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to convert data into string\n",
        "def standardize_sentiments(sentiments):\n",
        "    if isinstance(sentiments, list):\n",
        "        return ', '.join(sentiments)\n",
        "    return sentiments\n",
        "\n",
        "# apply the function\n",
        "df['gpt_sentiment_all'] = df['gpt_sentiment_all'].apply(standardize_sentiments)\n",
        "df['gpt_sentiment_4'] = df['gpt_sentiment_4'].apply(standardize_sentiments)\n",
        "df['gpt_sentiment_2'] = df['gpt_sentiment_2'].apply(standardize_sentiments)\n",
        "\n",
        "df.dropna(subset=['human_all', 'gpt_sentiment_all'], inplace=True)\n",
        "df.dropna(subset=['human_4', 'gpt_sentiment_4'], inplace=True)\n",
        "df.dropna(subset=['human_2', 'gpt_sentiment_2'], inplace=True)\n",
        "\n",
        "# Define the expected sentiment categories\n",
        "expected_all = ['Angry', 'Anxious', 'Excited', 'Happy', 'Relaxed', 'Sad', 'Serene', 'Grateful', 'Spooky']\n",
        "expected_4 = ['Angry/Anxious', 'Excited/Happy', 'Serene/Relaxed',  'Sad']\n",
        "expected_2 = ['Negative', 'Positive']\n",
        "\n",
        "# Filter the data to include only rows with expected categories\n",
        "df = df[df['gpt_sentiment_all'].isin(expected_all)]\n",
        "df = df[df['gpt_sentiment_4'].isin(expected_4)]\n",
        "df = df[df['gpt_sentiment_2'].isin(expected_2)]\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_all = accuracy_score(df['human_all'], df['gpt_sentiment_all'])\n",
        "accuracy_4 = accuracy_score(df['human_4'], df['gpt_sentiment_4'])\n",
        "accuracy_2 = accuracy_score(df['human_2'], df['gpt_sentiment_2'])\n",
        "\n",
        "print(f\"Accuracy for All Sentiments: {accuracy_all}\")\n",
        "print(f\"Accuracy for 4 Sentiments: {accuracy_4}\")\n",
        "print(f\"Accuracy for 2 Sentiments: {accuracy_2}\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report for All Sentiments:\")\n",
        "print(classification_report(df['human_all'], df['gpt_sentiment_all'], zero_division=0))\n",
        "\n",
        "print(\"\\nClassification Report for 4 Sentiments:\")\n",
        "print(classification_report(df['human_4'], df['gpt_sentiment_4'], zero_division=0))\n",
        "\n",
        "print(\"\\nClassification Report for 2 Sentiments:\")\n",
        "print(classification_report(df['human_2'], df['gpt_sentiment_2'], zero_division=0))"
      ],
      "metadata": {
        "id": "V6r4ZB2_4ZLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3945c33a-1f96-4394-89a4-0e2dce48227e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for All Sentiments: 0.5666666666666667\n",
            "Accuracy for 4 Sentiments: 0.5545454545454546\n",
            "Accuracy for 2 Sentiments: 0.7878787878787878\n",
            "\n",
            "Classification Report for All Sentiments:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.78      0.36      0.49        59\n",
            "     Anxious       0.61      0.17      0.26       138\n",
            "     Excited       0.40      0.71      0.51        62\n",
            "    Grateful       0.00      0.00      0.00         0\n",
            "       Happy       0.46      0.68      0.55       111\n",
            "     Relaxed       0.67      0.05      0.09       125\n",
            "         Sad       0.67      0.89      0.77       403\n",
            "      Serene       0.32      0.38      0.34        92\n",
            "      Spooky       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.57       990\n",
            "   macro avg       0.43      0.36      0.33       990\n",
            "weighted avg       0.60      0.57      0.51       990\n",
            "\n",
            "\n",
            "Classification Report for 4 Sentiments:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            " Angry/Anxious       0.86      0.06      0.11       197\n",
            " Excited/Happy       0.64      0.65      0.64       173\n",
            "           Sad       0.54      0.98      0.69       403\n",
            "Serene/Relaxed       0.44      0.14      0.22       217\n",
            "\n",
            "      accuracy                           0.55       990\n",
            "     macro avg       0.62      0.46      0.42       990\n",
            "  weighted avg       0.60      0.55      0.47       990\n",
            "\n",
            "\n",
            "Classification Report for 2 Sentiments:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.77      0.93      0.84       600\n",
            "    Positive       0.83      0.58      0.68       390\n",
            "\n",
            "    accuracy                           0.79       990\n",
            "   macro avg       0.80      0.75      0.76       990\n",
            "weighted avg       0.80      0.79      0.78       990\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_predictions_all = []\n",
        "incorrect_predictions_4 = []\n",
        "incorrect_predictions_2 = []\n",
        "\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    if row['human_all'] != row['gpt_sentiment_all']:\n",
        "        incorrect_predictions_all.append(row)\n",
        "    if row['human_4'] != row['gpt_sentiment_4']:\n",
        "        incorrect_predictions_4.append(row)\n",
        "    if row['human_2'] != row['gpt_sentiment_2']:\n",
        "        incorrect_predictions_2.append(row)\n",
        "\n",
        "df_incorrect_all = pd.DataFrame(incorrect_predictions_all)\n",
        "df_incorrect_4 = pd.DataFrame(incorrect_predictions_4)\n",
        "df_incorrect_2 = pd.DataFrame(incorrect_predictions_2)\n",
        "\n",
        "\n",
        "df_incorrect_all.to_csv('gpt3.5_errors_all.csv', index=False)\n",
        "df_incorrect_4.to_csv('gpt3.5_errors_4.csv', index=False)\n",
        "df_incorrect_2.to_csv('gpt3.5_errors_2.csv', index=False)\n",
        "\n",
        "print(f\"Saved {len(df_incorrect_all)} incorrect predictions for all sentiments to 'gpt3.5_errors_all.csv'\")\n",
        "print(f\"Saved {len(df_incorrect_4)} incorrect predictions for 4 sentiments to 'gpt3.5_errors_4.csv'\")\n",
        "print(f\"Saved {len(df_incorrect_2)} incorrect predictions for 2 sentiments to 'gpt3.5_errors_2.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvRoT5uJvs18",
        "outputId": "7b41a305-30b0-45a0-ec6b-e3cc53897ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 429 incorrect predictions for all sentiments to 'gpt3.5_errors_all.csv'\n",
            "Saved 441 incorrect predictions for 4 sentiments to 'gpt3.5_errors_4.csv'\n",
            "Saved 210 incorrect predictions for 2 sentiments to 'gpt3.5_errors_2.csv'\n"
          ]
        }
      ]
    }
  ]
}